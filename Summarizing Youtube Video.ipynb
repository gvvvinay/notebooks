{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain -q\n",
    "%pip install youtube_transcript_api faiss-gpu -q \n",
    "%pip install langchain-google-genai -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDINGS = GooglePalmEmbeddings()\n",
    "\n",
    "def create_db(video_url):\n",
    "  loader = YoutubeLoader.from_youtube_url(video_url)\n",
    "  transcript = loader.load()\n",
    "\n",
    "  splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "  docs = splitter.split_documents(transcript)\n",
    "\n",
    "  return FAISS.from_documents(docs, EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_db(db, query, k=4):\n",
    "  docs = db.similarity_search(query, k=k)\n",
    "\n",
    "  page_content = \" \".join([d.page_content for d in docs])\n",
    "\n",
    "  llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", convert_system_message_to_human=True)\n",
    "\n",
    "  prompt = PromptTemplate(\n",
    "      input_variables=[\"question\", \"docs\"],\n",
    "      template=\"\"\"\n",
    "        You are a helpful assistant that can answer questions about YouTube videos\n",
    "        based on the video's transcript. Given a question and a video transcript,\n",
    "        answer the question in a comprehensive and informative way,\n",
    "        using only the factual information from the transcript.\n",
    "\n",
    "        If you don't have enough information to answer the question, say \"I don't know.\"\n",
    "\n",
    "        Question: {question}\n",
    "\n",
    "        Transcript: {docs}\n",
    "        \"\"\",\n",
    "    )\n",
    "\n",
    "  chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "  response = chain.invoke({\"question\": query, \"docs\": page_content})\n",
    "\n",
    "  response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "  return response, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = 'https://www.youtube.com/watch?v=bSHp7WVpPgc'\n",
    "db = create_db(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "query = \"Can you summarize the video?\"\n",
    "response, docs = query_db(db, query)\n",
    "print(textwrap.fill(response, width=85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are they saying about opensoruce?\"\n",
    "response, docs = query_db(db, query)\n",
    "print(textwrap.fill(response, width=85))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
